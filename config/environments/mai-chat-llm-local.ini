# LOG Config
[LOG]
log_level=DEBUG
log_backtrace=True
log_diagnose=True
log_retention_days=30

[SERVICE]
port=8000
reload=False

[LLM-MODEL]
llm_model_type=LLAMA3
llm_model_path=C:/Projects/01.Python/MAI-CHAT-PROD/llm-wrapper/models/llama3-8b-q4/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf
llm_model_verbose=True
#llm_model_n_gpu_layers=36
llm_model_n_gpu_layers=-1
llm_model_n_ctx=8192
#llm_model_n_ctx=512
llm_model_n_threads=8
llm_model_n_batch=8
llm_model_max_tokens=1024
#llm_model_max_tokens=512
llm_model_temperature=0.6
llm_model_top_p=0.9
llm_model_streaming=False
llm_model_f16_kv=True
llm_model_repeat_penalty=1.1
llm_model_mirostat_mode=2

[API]
retrival_api=http://172.16.0.27:5010/v1/retriever

[LM-CHECK]
greetings_en=hello,hi,How are you,what's up,how are you,how do you do,oh
greetings_ko=안녕하세요,안녕,하이,반가워,반가워요,넌 누구니,이름이 뭐야,이름,이름 알려줘,이름 알려주세요,방가
endings_en=goodbye,bye,see you
endings_ko=고마워,바이
farewell_en=opps
farewell_ko=바보