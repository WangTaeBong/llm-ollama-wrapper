SSL:
  use_https: false
  ssl_keyfile: "c:/Projects/01.Python/MAI-CHAT-PROD/bot-controller/config/ssl/key.pem"
  ssl_certfile: "c:/Projects/01.Python/MAI-CHAT-PROD/bot-controller/config/ssl/cert.pem"

LOG:
  log_level: "DEBUG"
  uvicorn_log_level: "WARNING"
  log_backtrace: true
  log_diagnose: true
  log_retention_days: 30
  log_path: "./logs"
  log_filename: "MAIChat_LLM.log"
  uvicorn_log_filename: "uvicorn.log"
  uvicorn_access_log_filename: "uvicorn_access.log"
  uvicorn_error_log_filename: "uvicorn_error.log"

SERVICE:
  version: "1.8"
  port: 8000
  reload: false
  debug_mode: false
  enable_docs: false
  workers: 4

  allowed_origins:
    - "*"

HTTP:
  timeout: 60

SECURITY:
  access_password: "AI-success!"
  session_secret: "mai-chat-number1!"
  trusted_hosts: localhost, 127.0.0.1, 10.50.12.54
  rate_limit: 100
  rate_limit_window: 60

LLM_MODEL:
  llm_model_type: "OLLAMA"
  llm_model_path: "C:/Projects/01.Python/MAI-CHAT-PROD/llm-wrapper/models/10.8b-korean-instruct-q8-v1/10.8b-korean-instruct-q8-v1.gguf"
  llm_model_verbose: true
  llm_model_n_gpu_layers: -1
  llm_model_n_ctx: 25000
  llm_model_n_threads: 30
  llm_model_n_batch: 20
  llm_model_max_tokens: 1024
  llm_model_temperature: 0.0
  llm_model_top_p: 0.9
  llm_model_streaming: false
  llm_model_f16_kv: true
  llm_model_repeat_penalty: 1.1
  llm_model_mirostat_mode: 2

LLM:
  llm_backend: "vllm"
  steaming_enabled: true
  use_improved_history: true  # 개선된 히스토리 처리 사용
  max_history_turns: 5        # 최대 히스토리 턴 수
  query_rewrite: true         # 질문 재정의 기능 사용
  rewrite_timeout: 3.0        # 질문 재정의 최대 대기 시간(초)

VLLM:
  endpoint_url: "http://10.50.1.43:8020/generate"

OLLAMA:
  access_type: "URL"
  model_name: "aicess-mistral-nemo-korean:12b"
  ollama_url: "http://10.50.1.43:11434"
  temperature: 0.0
  mirostat: 2

API:
  retrival_api: "http://10.50.1.26:5010/v1/retriever"

CIRCUIT_BREAKER:
  failure_threshold: 3
  recovery_timeout: 60
  reset_timeout: 600

RETRIEVER:
  filter_flag: false

QUERY_FILTER:
  enabled: true
  ko_jamo: true
  arabia_num: true
  wild_char: true

LM_CHECK:
  query_dict_config_path: "C:/Projects/01.Python/MAI-CHAT-PROD/llm-ollama-wrapper/config/prompts/query_check_dict.json"
  query_lang_key: "ko,en,jp,cn"
  query_dict_key: "greetings,endings,farewells"

PROMPT:
  faq_type: "komico_faq_it,komico_faq_lab"
  source_priority: false
  source_type: "mico_hr_it,aicess_hr,aicess_m"
  none_source_type: "komico_faq_it,komico_faq_lab,komico_voc"
  source_count: 2
  json_config_path: "C:/Projects/01.Python/MAI-CHAT-PROD/llm-ollama-wrapper/config/prompts"
  llm_prompt_path: "C:/Projects/01.Python/MAI-CHAT-PROD/llm-ollama-wrapper/config/prompts/mai-chat-prompt_ko.json"
  history_prompt_path: "C:/Projects/01.Python/MAI-CHAT-PROD/llm-ollama-wrapper/config/prompts/mai-chat-history-prompt.json"

VOC:
  voc_type: "komico_voc"
  gw_doc_id_prefix_url: "https://intermico.com/app/approval/document"
  check_gw_word_link: "전자결재 링크정보"
  check_gw_word: "전자결재 문서번호"
  check_block_line: "---------"
  gw_doc_id_link_url_pattern: "(https://intermico.com/app/approval/document((?:\/[\\w]*)))"
  gw_doc_id_link_correct_pattern: "https://intermico.com/app/approval/document(?:\/\\d{8})"

WEB_SEARCH:
  use_flag: true
  document_add_type: 1
  region: "kr-kr"
  max_results: 5

CHAT_HISTORY:
  enabled: true

REDIS:
  host: "10.50.1.26"
  port: 6379
  password: "AI-success!"
  database: 0
  ttl_enabled: true
  ttl_time: 1800
  get_message_count: 10
  max_turns: 10

CACHE:
  max_size: 200
  chain_ttl: 3600
  max_concurrent_tasks: 50

NLP_MODELS:
  sentence_model_path: "C:/Projects/01.Python/MAI-CHAT-PROD/llm-ollama-wrapper/models/sentence-transformer/distiluse-base-multilingual-cased-v2"
  bert_model_path: "C:/Projects/01.Python/MAI-CHAT-PROD/llm-ollama-wrapper/models/bert/bert-base-multilingual-cased"
