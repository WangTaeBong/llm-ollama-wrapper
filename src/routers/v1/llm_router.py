import logging

from fastapi import APIRouter, Depends, HTTPException, status

from src.schema.chat_req import ChatRequest
from src.schema.chat_res import ChatResponse
from src.services.llm_ollama_process import ChatService

# Configure logger
logger = logging.getLogger(__name__)

# Router configuration
llm_router = APIRouter(prefix='/v1', tags=["LLM Chat"])


async def log_request(request: ChatRequest) -> ChatRequest:
    """
    Dependency function for logging incoming requests.

    Logs the content of chat requests in debug mode with sensitive information masked.
    This function maintains a balance between comprehensive logging for debugging
    purposes and security/privacy concerns.

    Args:
        request (ChatRequest): The original chat request object

    Returns:
        ChatRequest: The unmodified original request object (passed through)
    """
    # Create a deep copy of the request to avoid modifying the original
    safe_request = request.copy(deep=True)

    # Mask sensitive information (if present)
    if hasattr(safe_request, 'api_key') and getattr(safe_request, 'api_key', None):
        setattr(safe_request, 'api_key', "********")  # Mask API key

    # Log basic request info at INFO level
    logger.info(f"Request[{safe_request.meta.rag_sys_info}/{safe_request.meta.session_id}] {safe_request.chat.user}")

    # Log detailed request data at DEBUG level
    logger.debug(f"Received chat request: {safe_request}")

    return request


def get_chat_service(request: ChatRequest) -> ChatService:
    """
    Dependency function for creating a ChatService instance.

    Initializes and returns a new ChatService instance configured with the
    provided request parameters. This dependency injection approach simplifies
    testing and allows for better separation of concerns.

    Args:
        request (ChatRequest): The validated chat request object

    Returns:
        ChatService: An initialized ChatService instance ready to process the request
    """
    return ChatService(request)


@llm_router.post(
    path="/chat",
    response_model=ChatResponse,
    summary="Process chat requests",
    description="Process user messages and generate responses using the LLM service.",
    response_description="Chat response generated by the LLM",
    status_code=status.HTTP_200_OK,
    responses={
        400: {"description": "Invalid request parameters or empty response"},
        500: {"description": "Internal server error"}
    }
)
async def chat(
        request: ChatRequest = Depends(log_request),
        chat_service: ChatService = Depends(get_chat_service),
) -> ChatResponse:
    """
    Endpoint for processing chat requests.

    This endpoint handles the entire lifecycle of a chat request:
    1. Receives and validates the user's message
    2. Processes the message through the LLM service
    3. Returns the generated response or appropriate error

    The function uses FastAPI's dependency injection system to:
    - Log the incoming request (via log_request)
    - Initialize the chat service (via get_chat_service)

    Args:
        request (ChatRequest): The validated chat request data
        chat_service (ChatService): The initialized chat service instance

    Returns:
        ChatResponse: The processed chat response from the LLM

    Raises:
        HTTPException(400): For validation failures or empty responses
        HTTPException(500): For unexpected server errors
    """
    try:
        # Process the chat request
        response = await chat_service.process_chat()

        # Verify we received a valid response
        if not response:
            logger.warning("Empty response received from ChatService")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Chat service returned an empty response",
            )

        return response

    except ValueError as ve:
        # Handle validation errors
        error_msg = str(ve)
        logger.warning(f"Validation error in chat request: {error_msg}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=error_msg
        )

    except HTTPException:
        # Re-raise any existing HTTPExceptions
        raise

    except Exception as e:
        # Handle unexpected errors with a unique reference ID for tracing
        error_id = id(e)  # Generate unique ID for this error instance
        logger.exception(f"Unexpected error in chat endpoint [ID: {error_id}]: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Internal server error occurred. Reference ID: {error_id}",
        )
